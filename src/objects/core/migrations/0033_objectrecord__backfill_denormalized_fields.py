# Generated by Django 5.2.3 on 2025-09-29 08:19

import os
import random
import threading
from concurrent.futures import ThreadPoolExecutor
from time import sleep

from django.db import connection, migrations, transaction

from structlog import get_logger
from tqdm import tqdm

logger = get_logger(__name__)


BATCH_SIZE = int(os.getenv("OBJECTRECORD_MIGRATION_0033_BATCH_SIZE", 2_000))
NUM_WORKERS = int(os.getenv("OBJECTRECORD_MIGRATION_0033_NUM_WORKERS", 4))


def backfill_object_type_batch_concurrent(cursor):
    """
    Grab a batch of rows with _object_type_id IS NULL and update them.
    SKIP LOCKED ensures multiple workers won't update the same row.
    """
    cursor.execute(
        """
        WITH cte AS (
            SELECT r.id, o.object_type_id
            FROM core_objectrecord r
            JOIN core_object o ON r.object_id = o.id
            WHERE r._object_type_id IS NULL
            FOR UPDATE SKIP LOCKED
            LIMIT %s
        )
        UPDATE core_objectrecord r
        SET _object_type_id = cte.object_type_id
        FROM cte
        WHERE r.id = cte.id;
    """,
        [BATCH_SIZE],
    )

    return cursor.rowcount


def worker(apps, progress):
    """
    Worker that keeps grabbing batches until none are left.
    """
    # Stagger the workers to avoid synchronized bursts of commit I/O
    delay = random.uniform(0.5, 1.5)
    sleep(delay)

    while True:
        with transaction.atomic():
            with connection.cursor() as cursor:
                cursor.execute("SET LOCAL synchronous_commit = OFF;")
                num_updated = backfill_object_type_batch_concurrent(cursor)

                if num_updated == 0:
                    sleep(0.5)
                    break

                progress.update(num_updated)


def forward(apps, schema_editor):
    """
    Spin up NUM_WORKERS parallel workers to process the table concurrently.
    """
    ObjectRecord = apps.get_model("core", "ObjectRecord")
    total_records = ObjectRecord.objects.count()

    # Progress bar
    lock = threading.Lock()
    tqdm.set_lock(lock)  # make tqdm thread-safe
    progress = tqdm(
        total=total_records, desc="Backfilling ObjectRecords", smoothing=0.1
    )

    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
        futures = [executor.submit(worker, apps, progress) for _ in range(NUM_WORKERS)]

        for f in futures:
            f.result()


class Migration(migrations.Migration):
    atomic = False
    dependencies = [
        ("core", "0032_objectrecord__object_type"),
    ]

    operations = [
        migrations.RunPython(forward, migrations.RunPython.noop),
    ]
